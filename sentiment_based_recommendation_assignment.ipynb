{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNz5NagZOyFuuvnQ94aF3o/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detkartik/upgrad_assignment/blob/master/sentiment_based_recommendation_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Libraries"
      ],
      "metadata": {
        "id": "J6QJerjpcH8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import cross_validate, train_test_split as surprise_train_test_split\n",
        "from surprise.accuracy import rmse\n",
        "from google.colab import drive\n",
        "from surprise.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "6Aec1bNucL8w"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load and Inspect Data"
      ],
      "metadata": {
        "id": "UdnDYfyLcOyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/MyDrive/sample30 (1).csv')\n",
        "\n",
        "# Display first few rows and summary info\n",
        "print(data.head())\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne_EClHOcWua",
        "outputId": "8835dfae-e72d-48d9-d944-345181ec6587"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                     id            brand  \\\n",
            "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
            "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
            "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
            "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
            "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
            "\n",
            "                                          categories  \\\n",
            "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
            "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
            "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
            "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
            "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
            "\n",
            "                         manufacturer  \\\n",
            "0  Universal Music Group / Cash Money   \n",
            "1                            Lundberg   \n",
            "2                            Lundberg   \n",
            "3                                 K-Y   \n",
            "4                                 K-Y   \n",
            "\n",
            "                                         name              reviews_date  \\\n",
            "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
            "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
            "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
            "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
            "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
            "\n",
            "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
            "0                 NaN                 NaN               5   \n",
            "1                True                 NaN               5   \n",
            "2                True                 NaN               5   \n",
            "3               False               False               1   \n",
            "4               False               False               1   \n",
            "\n",
            "                                        reviews_text reviews_title  \\\n",
            "0  i love this album. it's very good. more to the...  Just Awesome   \n",
            "1  Good flavor. This review was collected as part...          Good   \n",
            "2                                       Good flavor.          Good   \n",
            "3  I read through the reviews on here before look...  Disappointed   \n",
            "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
            "\n",
            "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
            "0      Los Angeles                  NaN           joshua       Positive  \n",
            "1              NaN                  NaN        dorothy w       Positive  \n",
            "2              NaN                  NaN        dorothy w       Positive  \n",
            "3              NaN                  NaN          rebecca       Negative  \n",
            "4              NaN                  NaN        walker557       Negative  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30000 entries, 0 to 29999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    30000 non-null  object\n",
            " 1   brand                 30000 non-null  object\n",
            " 2   categories            30000 non-null  object\n",
            " 3   manufacturer          29859 non-null  object\n",
            " 4   name                  30000 non-null  object\n",
            " 5   reviews_date          29954 non-null  object\n",
            " 6   reviews_didPurchase   15932 non-null  object\n",
            " 7   reviews_doRecommend   27430 non-null  object\n",
            " 8   reviews_rating        30000 non-null  int64 \n",
            " 9   reviews_text          30000 non-null  object\n",
            " 10  reviews_title         29810 non-null  object\n",
            " 11  reviews_userCity      1929 non-null   object\n",
            " 12  reviews_userProvince  170 non-null    object\n",
            " 13  reviews_username      29937 non-null  object\n",
            " 14  user_sentiment        29999 non-null  object\n",
            "dtypes: int64(1), object(14)\n",
            "memory usage: 3.4+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data Cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "bte58JTdcfrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna(subset=['reviews_text', 'user_sentiment'])\n",
        "data['reviews_text'] = data['reviews_text'].str.lower().str.replace('[^\\w\\s]', '')\n",
        "data['user_sentiment'] = data['user_sentiment'].map({'Positive': 1, 'Negative': 0})\n"
      ],
      "metadata": {
        "id": "Eee9WG_ha2nv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Text Processing and Feature Extraction"
      ],
      "metadata": {
        "id": "aIqOWV-xcs3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize text data for sentiment analysis\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(data['reviews_text'])\n",
        "y = data['user_sentiment']\n",
        "\n",
        "# Example: TF-IDF Vectorization for content-based filtering\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "content_vectors = tfidf_vectorizer.fit_transform(data['name'] + ' ' + data['categories'])"
      ],
      "metadata": {
        "id": "Qxr_wm0qcw0g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Machine Learning Models (Sentiment Analysis)"
      ],
      "metadata": {
        "id": "tzZZIIHkc80o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "logreg_model = LogisticRegression()\n",
        "logreg_model.fit(X_train, y_train)\n",
        "y_pred = logreg_model.predict(X_test)\n",
        "print('Logistic Regression Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1wm-sgpb9GJ",
        "outputId": "648c9731-c46d-49f6-97c2-45bd0628befc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9448333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.67      0.73       653\n",
            "           1       0.96      0.98      0.97      5347\n",
            "\n",
            "    accuracy                           0.94      6000\n",
            "   macro avg       0.88      0.83      0.85      6000\n",
            "weighted avg       0.94      0.94      0.94      6000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Recommendation System (Collaborative Filtering)"
      ],
      "metadata": {
        "id": "rzXLIUcld2cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P71cgZRKRwSp",
        "outputId": "05664997-0345-4aae-b1c5-4d826805ed6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the data from the DataFrame\n",
        "data_surprise = Dataset.load_from_df(data[['reviews_username', 'name', 'reviews_rating']], reader)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "trainset, testset = train_test_split(data_surprise, test_size=0.25)\n",
        "\n",
        "# Use the SVD algorithm\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Test the algorithm on the testset\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Compute and print the RMSE\n",
        "print('RMSE:', rmse(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuQRBgpuSyC5",
        "outputId": "91845ec3-58c7-4913-fc62-899e0f740b42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.7678\n",
            "RMSE: 0.7678475253054363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Content-Based Filtering"
      ],
      "metadata": {
        "id": "_h0UwhQKeAIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Combine relevant features for content-based filtering\n",
        "data['combined_features'] = data['name'] + \" \" + data['categories'] + \" \" + data['reviews_text']\n",
        "\n",
        "# Vectorize the combined features\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "content_vectors = vectorizer.fit_transform(data['combined_features'])\n",
        "\n",
        "# # Compute cosine similarity matrix\n",
        "batch_size = 1000\n",
        "num_rows = content_vectors.shape[0]\n",
        "cosine_sim = np.zeros((num_rows, num_rows))  # Initialize cosine similarity matrix\n",
        "\n",
        "# Compute cosine similarity in batches\n",
        "for i in range(0, num_rows, batch_size):\n",
        "    start_idx = i\n",
        "    end_idx = min(i + batch_size, num_rows)\n",
        "    batch_similarity = cosine_similarity(content_vectors[start_idx:end_idx], content_vectors)\n",
        "    cosine_sim[start_idx:end_idx] = batch_similarity\n"
      ],
      "metadata": {
        "id": "9WqO3pj3UhOi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_content_recommendations(product_id, cosine_sim=cosine_sim):\n",
        "    try:\n",
        "        idx = data.index[data['id'] == product_id][0]\n",
        "    except IndexError:\n",
        "        print(f\"Product ID '{product_id}' not found in the dataset.\")\n",
        "        return None\n",
        "\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:6]  # Get top 5 similar products\n",
        "    product_indices = [i[0] for i in sim_scores]\n",
        "    return data['name'].iloc[product_indices]\n",
        "\n",
        "# Example usage\n",
        "print(get_content_recommendations('1'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypw5gP2cWxgQ",
        "outputId": "5d50bff3-0f33-4ee9-b4e8-bf6b6a5da131"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product ID '1' not found in the dataset.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zB68x81e3jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/recommend-products', methods=['POST'])\n",
        "def recommend_products():\n",
        "    data = request.json\n",
        "    product_id = data['product_id']\n",
        "\n",
        "    # Call the recommendation function\n",
        "    recommendations = get_content_recommendations(product_id)\n",
        "\n",
        "    if recommendations:\n",
        "        return jsonify({'recommendations': recommendations})\n",
        "    else:\n",
        "        return jsonify({'error': f\"Product ID '{product_id}' not found.\"}), 404\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTyO3N5rYXaL",
        "outputId": "2f7fc5e1-f9fd-4112-f4d0-31265eefb627"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}