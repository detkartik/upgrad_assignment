{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOw+PfKGcBviDk6Th/r9fy1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detkartik/upgrad_assignment/blob/master/sentiment_based_recommendation_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/sample30 (1).csv')\n",
        "\n",
        "# Drop rows with missing values in 'reviews_text' and 'user_sentiment'\n",
        "data = data.dropna(subset=['reviews_text', 'user_sentiment'])\n",
        "\n",
        "# Clean text data\n",
        "data['reviews_text'] = data['reviews_text'].str.lower().str.replace('[^\\w\\s]', '')\n",
        "\n",
        "# Encode user sentiment\n",
        "data['user_sentiment'] = data['user_sentiment'].map({'Positive': 1, 'Negative': 0})\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['reviews_text'], data['user_sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text data\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7ZqUDTZQ67z",
        "outputId": "84cfb0c5-2dae-4d81-fda7-13a38d85df2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-23eead3fa912>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['reviews_text'] = data['reviews_text'].str.lower().str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-1-23eead3fa912>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['user_sentiment'] = data['user_sentiment'].map({'Positive': 1, 'Negative': 0})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9448333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.67      0.73       653\n",
            "           1       0.96      0.98      0.97      5347\n",
            "\n",
            "    accuracy                           0.94      6000\n",
            "   macro avg       0.88      0.83      0.85      6000\n",
            "weighted avg       0.94      0.94      0.94      6000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P71cgZRKRwSp",
        "outputId": "05664997-0345-4aae-b1c5-4d826805ed6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the data from the DataFrame\n",
        "data_surprise = Dataset.load_from_df(data[['reviews_username', 'name', 'reviews_rating']], reader)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "trainset, testset = train_test_split(data_surprise, test_size=0.25)\n",
        "\n",
        "# Use the SVD algorithm\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Test the algorithm on the testset\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Compute and print the RMSE\n",
        "print('RMSE:', accuracy.rmse(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuQRBgpuSyC5",
        "outputId": "68c3fa39-fd87-4b84-ddcf-54c4943c3114"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.7743\n",
            "RMSE: 0.7742738926506441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Combine relevant features for content-based filtering\n",
        "data['combined_features'] = data['name'] + \" \" + data['categories'] + \" \" + data['reviews_text']\n",
        "\n",
        "# Vectorize the combined features\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "content_vectors = vectorizer.fit_transform(data['combined_features'])\n",
        "\n",
        "# # Compute cosine similarity matrix\n",
        "batch_size = 1000\n",
        "num_rows = content_vectors.shape[0]\n",
        "cosine_sim = np.zeros((num_rows, num_rows))  # Initialize cosine similarity matrix\n",
        "\n",
        "# Compute cosine similarity in batches\n",
        "for i in range(0, num_rows, batch_size):\n",
        "    start_idx = i\n",
        "    end_idx = min(i + batch_size, num_rows)\n",
        "    batch_similarity = cosine_similarity(content_vectors[start_idx:end_idx], content_vectors)\n",
        "    cosine_sim[start_idx:end_idx] = batch_similarity\n"
      ],
      "metadata": {
        "id": "9WqO3pj3UhOi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_content_recommendations(product_id, cosine_sim=cosine_sim):\n",
        "    try:\n",
        "        idx = data.index[data['id'] == product_id][0]\n",
        "    except IndexError:\n",
        "        print(f\"Product ID '{product_id}' not found in the dataset.\")\n",
        "        return None\n",
        "\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:6]  # Get top 5 similar products\n",
        "    product_indices = [i[0] for i in sim_scores]\n",
        "    return data['name'].iloc[product_indices]\n",
        "\n",
        "# Example usage\n",
        "print(get_content_recommendations('1'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypw5gP2cWxgQ",
        "outputId": "5d50bff3-0f33-4ee9-b4e8-bf6b6a5da131"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product ID '1' not found in the dataset.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/recommend-products', methods=['POST'])\n",
        "def recommend_products():\n",
        "    data = request.json\n",
        "    product_id = data['product_id']\n",
        "\n",
        "    # Call the recommendation function\n",
        "    recommendations = get_content_recommendations(product_id)\n",
        "\n",
        "    if recommendations:\n",
        "        return jsonify({'recommendations': recommendations})\n",
        "    else:\n",
        "        return jsonify({'error': f\"Product ID '{product_id}' not found.\"}), 404\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTyO3N5rYXaL",
        "outputId": "2f7fc5e1-f9fd-4112-f4d0-31265eefb627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}